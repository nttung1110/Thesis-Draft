
[epoch_1, batch_50] loss: 0.579
[epoch_1, batch_100] loss: 0.447
[epoch_1, batch_150] loss: 0.440
[epoch_1, batch_200] loss: 0.418
[epoch_1, batch_250] loss: 0.387
[epoch_1, batch_300] loss: 0.386
[epoch_1, batch_350] loss: 0.387
[epoch_1, batch_400] loss: 0.367
[epoch_1, batch_450] loss: 0.350
[epoch_1, batch_500] loss: 0.333
[epoch_1, batch_550] loss: 0.295
[epoch_1, batch_600] loss: 0.297
[epoch_1, batch_650] loss: 0.284
[epoch_1, batch_700] loss: 0.259
[epoch_1, batch_750] loss: 0.249
[epoch_1, batch_800] loss: 0.241
[epoch_1, batch_850] loss: 0.233
[epoch_1, batch_900] loss: 0.210
[epoch_1, batch_950] loss: 0.189
[epoch_1, batch_1000] loss: 0.182
[epoch_1, batch_1050] loss: 0.175
[epoch_1, batch_1100] loss: 0.156
[epoch_1, batch_1150] loss: 0.164
[epoch_1, batch_1200] loss: 0.153
[epoch_1, batch_1250] loss: 0.130
[epoch_1, batch_1300] loss: 0.137
[epoch_1, batch_1350] loss: 0.139
[epoch_2, batch_50] loss: 0.263
[epoch_2, batch_100] loss: 0.134
[epoch_2, batch_150] loss: 0.133
[epoch_2, batch_200] loss: 0.137
[epoch_2, batch_250] loss: 0.111
[epoch_2, batch_300] loss: 0.103
[epoch_2, batch_350] loss: 0.123
[epoch_2, batch_400] loss: 0.123
[epoch_2, batch_450] loss: 0.106
[epoch_2, batch_500] loss: 0.099
[epoch_2, batch_550] loss: 0.112
[epoch_2, batch_600] loss: 0.102
[epoch_2, batch_650] loss: 0.118
[epoch_2, batch_700] loss: 0.109
[epoch_2, batch_750] loss: 0.121
[epoch_2, batch_800] loss: 0.123
[epoch_2, batch_850] loss: 0.101
[epoch_2, batch_900] loss: 0.108
[epoch_2, batch_950] loss: 0.107
[epoch_2, batch_1000] loss: 0.103
[epoch_2, batch_1050] loss: 0.108
[epoch_2, batch_1100] loss: 0.085
[epoch_2, batch_1150] loss: 0.134
[epoch_2, batch_1200] loss: 0.138
[epoch_2, batch_1250] loss: 0.096
[epoch_2, batch_1300] loss: 0.102
[epoch_2, batch_1350] loss: 0.091
[epoch_3, batch_50] loss: 0.178
[epoch_3, batch_100] loss: 0.098
[epoch_3, batch_150] loss: 0.094
[epoch_3, batch_200] loss: 0.103
[epoch_3, batch_250] loss: 0.096
[epoch_3, batch_300] loss: 0.087
[epoch_3, batch_350] loss: 0.099
[epoch_3, batch_400] loss: 0.091
[epoch_3, batch_450] loss: 0.094
[epoch_3, batch_500] loss: 0.106
[epoch_3, batch_550] loss: 0.111
[epoch_3, batch_600] loss: 0.081
[epoch_3, batch_650] loss: 0.075
[epoch_3, batch_700] loss: 0.092
[epoch_3, batch_750] loss: 0.085
[epoch_3, batch_800] loss: 0.085
[epoch_3, batch_850] loss: 0.087
[epoch_3, batch_900] loss: 0.093
[epoch_3, batch_950] loss: 0.107
[epoch_3, batch_1000] loss: 0.107
[epoch_3, batch_1050] loss: 0.099
[epoch_3, batch_1100] loss: 0.080
[epoch_3, batch_1150] loss: 0.090
[epoch_3, batch_1200] loss: 0.087
[epoch_3, batch_1250] loss: 0.074
[epoch_3, batch_1300] loss: 0.079
[epoch_3, batch_1350] loss: 0.087
[epoch_4, batch_50] loss: 0.185
[epoch_4, batch_100] loss: 0.085
[epoch_4, batch_150] loss: 0.077
[epoch_4, batch_200] loss: 0.089
[epoch_4, batch_250] loss: 0.083
[epoch_4, batch_300] loss: 0.071
[epoch_4, batch_350] loss: 0.080
[epoch_4, batch_400] loss: 0.079
[epoch_4, batch_450] loss: 0.075
[epoch_4, batch_500] loss: 0.075
[epoch_4, batch_550] loss: 0.081
[epoch_4, batch_600] loss: 0.086
[epoch_4, batch_650] loss: 0.063
[epoch_4, batch_700] loss: 0.079
[epoch_4, batch_750] loss: 0.087
[epoch_4, batch_800] loss: 0.075
[epoch_4, batch_850] loss: 0.074
[epoch_4, batch_900] loss: 0.071
[epoch_4, batch_950] loss: 0.086
[epoch_4, batch_1000] loss: 0.091
[epoch_4, batch_1050] loss: 0.074
[epoch_4, batch_1100] loss: 0.083
[epoch_4, batch_1150] loss: 0.089
[epoch_4, batch_1200] loss: 0.082
[epoch_4, batch_1250] loss: 0.067
[epoch_4, batch_1300] loss: 0.093
[epoch_4, batch_1350] loss: 0.081
[epoch_5, batch_50] loss: 0.158
[epoch_5, batch_100] loss: 0.075
[epoch_5, batch_150] loss: 0.069
[epoch_5, batch_200] loss: 0.092
[epoch_5, batch_250] loss: 0.073
[epoch_5, batch_300] loss: 0.064
[epoch_5, batch_350] loss: 0.087
[epoch_5, batch_400] loss: 0.081
[epoch_5, batch_450] loss: 0.075
[epoch_5, batch_500] loss: 0.078
[epoch_5, batch_550] loss: 0.082
[epoch_5, batch_600] loss: 0.094
[epoch_5, batch_650] loss: 0.074
[epoch_5, batch_700] loss: 0.071
[epoch_5, batch_750] loss: 0.086
[epoch_5, batch_800] loss: 0.086
[epoch_5, batch_850] loss: 0.061
[epoch_5, batch_900] loss: 0.064
[epoch_5, batch_950] loss: 0.066
[epoch_5, batch_1000] loss: 0.060
[epoch_5, batch_1050] loss: 0.091
[epoch_5, batch_1100] loss: 0.062
[epoch_5, batch_1150] loss: 0.066
[epoch_5, batch_1200] loss: 0.077
[epoch_5, batch_1250] loss: 0.074
[epoch_5, batch_1300] loss: 0.070
[epoch_5, batch_1350] loss: 0.054
[epoch_6, batch_50] loss: 0.120
[epoch_6, batch_100] loss: 0.064
[epoch_6, batch_150] loss: 0.070
[epoch_6, batch_200] loss: 0.062
[epoch_6, batch_250] loss: 0.068
[epoch_6, batch_300] loss: 0.070
[epoch_6, batch_350] loss: 0.067
[epoch_6, batch_400] loss: 0.064
[epoch_6, batch_450] loss: 0.082
[epoch_6, batch_500] loss: 0.077
[epoch_6, batch_550] loss: 0.085
[epoch_6, batch_600] loss: 0.068
[epoch_6, batch_650] loss: 0.063
[epoch_6, batch_700] loss: 0.059
[epoch_6, batch_750] loss: 0.076
[epoch_6, batch_800] loss: 0.071
[epoch_6, batch_850] loss: 0.056
[epoch_6, batch_900] loss: 0.059
[epoch_6, batch_950] loss: 0.060
[epoch_6, batch_1000] loss: 0.058
[epoch_6, batch_1050] loss: 0.059
[epoch_6, batch_1100] loss: 0.074
[epoch_6, batch_1150] loss: 0.063
[epoch_6, batch_1200] loss: 0.080
[epoch_6, batch_1250] loss: 0.070
[epoch_6, batch_1300] loss: 0.065
[epoch_6, batch_1350] loss: 0.051
[epoch_7, batch_50] loss: 0.175
[epoch_7, batch_100] loss: 0.067
[epoch_7, batch_150] loss: 0.063
[epoch_7, batch_200] loss: 0.058
[epoch_7, batch_250] loss: 0.059
[epoch_7, batch_300] loss: 0.054
[epoch_7, batch_350] loss: 0.060
[epoch_7, batch_400] loss: 0.067
[epoch_7, batch_450] loss: 0.064
[epoch_7, batch_500] loss: 0.064
[epoch_7, batch_550] loss: 0.061
[epoch_7, batch_600] loss: 0.089
[epoch_7, batch_650] loss: 0.069
[epoch_7, batch_700] loss: 0.072
[epoch_7, batch_750] loss: 0.052
[epoch_7, batch_800] loss: 0.067
[epoch_7, batch_850] loss: 0.073
[epoch_7, batch_900] loss: 0.065
[epoch_7, batch_950] loss: 0.073
[epoch_7, batch_1000] loss: 0.066
[epoch_7, batch_1050] loss: 0.066
[epoch_7, batch_1100] loss: 0.054
[epoch_7, batch_1150] loss: 0.059
[epoch_7, batch_1200] loss: 0.051
[epoch_7, batch_1250] loss: 0.071
[epoch_7, batch_1300] loss: 0.050
[epoch_7, batch_1350] loss: 0.053
[epoch_8, batch_50] loss: 0.086
[epoch_8, batch_100] loss: 0.064
[epoch_8, batch_150] loss: 0.061
[epoch_8, batch_200] loss: 0.055
[epoch_8, batch_250] loss: 0.067
[epoch_8, batch_300] loss: 0.050
[epoch_8, batch_350] loss: 0.060
[epoch_8, batch_400] loss: 0.081
[epoch_8, batch_450] loss: 0.061
[epoch_8, batch_500] loss: 0.058
[epoch_8, batch_550] loss: 0.063
[epoch_8, batch_600] loss: 0.050
[epoch_8, batch_650] loss: 0.056
[epoch_8, batch_700] loss: 0.058
[epoch_8, batch_750] loss: 0.068
[epoch_8, batch_800] loss: 0.064
[epoch_8, batch_850] loss: 0.044
[epoch_8, batch_900] loss: 0.061
[epoch_8, batch_950] loss: 0.069
[epoch_8, batch_1000] loss: 0.053
[epoch_8, batch_1050] loss: 0.053
[epoch_8, batch_1100] loss: 0.060
[epoch_8, batch_1150] loss: 0.057
[epoch_8, batch_1200] loss: 0.048
[epoch_8, batch_1250] loss: 0.060
[epoch_8, batch_1300] loss: 0.064
[epoch_8, batch_1350] loss: 0.065
[epoch_9, batch_50] loss: 0.107
[epoch_9, batch_100] loss: 0.060
[epoch_9, batch_150] loss: 0.058
[epoch_9, batch_200] loss: 0.052
[epoch_9, batch_250] loss: 0.054
[epoch_9, batch_300] loss: 0.063
[epoch_9, batch_350] loss: 0.055
[epoch_9, batch_400] loss: 0.063
[epoch_9, batch_450] loss: 0.058
[epoch_9, batch_500] loss: 0.050
[epoch_9, batch_550] loss: 0.057
[epoch_9, batch_600] loss: 0.047
[epoch_9, batch_650] loss: 0.060
[epoch_9, batch_700] loss: 0.056
[epoch_9, batch_750] loss: 0.051
[epoch_9, batch_800] loss: 0.063
[epoch_9, batch_850] loss: 0.061
[epoch_9, batch_900] loss: 0.049
[epoch_9, batch_950] loss: 0.058
[epoch_9, batch_1000] loss: 0.047
[epoch_9, batch_1050] loss: 0.053
[epoch_9, batch_1100] loss: 0.068
[epoch_9, batch_1150] loss: 0.058
[epoch_9, batch_1200] loss: 0.059
[epoch_9, batch_1250] loss: 0.051
[epoch_9, batch_1300] loss: 0.053
[epoch_9, batch_1350] loss: 0.035
[epoch_10, batch_50] loss: 0.105
[epoch_10, batch_100] loss: 0.045
[epoch_10, batch_150] loss: 0.048
[epoch_10, batch_200] loss: 0.048
[epoch_10, batch_250] loss: 0.050
[epoch_10, batch_300] loss: 0.040
[epoch_10, batch_350] loss: 0.051
[epoch_10, batch_400] loss: 0.049
[epoch_10, batch_450] loss: 0.067
[epoch_10, batch_500] loss: 0.070
[epoch_10, batch_550] loss: 0.051
[epoch_10, batch_600] loss: 0.052
[epoch_10, batch_650] loss: 0.052
[epoch_10, batch_700] loss: 0.050
[epoch_10, batch_750] loss: 0.058
[epoch_10, batch_800] loss: 0.061
[epoch_10, batch_850] loss: 0.037
[epoch_10, batch_900] loss: 0.037
[epoch_10, batch_950] loss: 0.045
[epoch_10, batch_1000] loss: 0.053
[epoch_10, batch_1050] loss: 0.039
[epoch_10, batch_1100] loss: 0.069
[epoch_10, batch_1150] loss: 0.060
[epoch_10, batch_1200] loss: 0.042
[epoch_10, batch_1250] loss: 0.045
[epoch_10, batch_1300] loss: 0.051
[epoch_10, batch_1350] loss: 0.045
[epoch_11, batch_50] loss: 0.092
[epoch_11, batch_100] loss: 0.056
[epoch_11, batch_150] loss: 0.049
[epoch_11, batch_200] loss: 0.056
[epoch_11, batch_250] loss: 0.047
[epoch_11, batch_300] loss: 0.062
[epoch_11, batch_350] loss: 0.049
[epoch_11, batch_400] loss: 0.043
[epoch_11, batch_450] loss: 0.046
[epoch_11, batch_500] loss: 0.047
[epoch_11, batch_550] loss: 0.048
[epoch_11, batch_600] loss: 0.049
[epoch_11, batch_650] loss: 0.062
[epoch_11, batch_700] loss: 0.042
[epoch_11, batch_750] loss: 0.039
[epoch_11, batch_800] loss: 0.052
[epoch_11, batch_850] loss: 0.049
[epoch_11, batch_900] loss: 0.041
[epoch_11, batch_950] loss: 0.046
[epoch_11, batch_1000] loss: 0.043
[epoch_11, batch_1050] loss: 0.046
[epoch_11, batch_1100] loss: 0.052
[epoch_11, batch_1150] loss: 0.044
[epoch_11, batch_1200] loss: 0.038
[epoch_11, batch_1250] loss: 0.039
[epoch_11, batch_1300] loss: 0.052
[epoch_11, batch_1350] loss: 0.052
[epoch_12, batch_50] loss: 0.092
[epoch_12, batch_100] loss: 0.043
[epoch_12, batch_150] loss: 0.044
[epoch_12, batch_200] loss: 0.044
[epoch_12, batch_250] loss: 0.049
[epoch_12, batch_300] loss: 0.044
[epoch_12, batch_350] loss: 0.044
[epoch_12, batch_400] loss: 0.052
[epoch_12, batch_450] loss: 0.038
[epoch_12, batch_500] loss: 0.050
[epoch_12, batch_550] loss: 0.058
[epoch_12, batch_600] loss: 0.045
[epoch_12, batch_650] loss: 0.040
[epoch_12, batch_700] loss: 0.042
[epoch_12, batch_750] loss: 0.048
[epoch_12, batch_800] loss: 0.053
[epoch_12, batch_850] loss: 0.050
[epoch_12, batch_900] loss: 0.047
[epoch_12, batch_950] loss: 0.045
[epoch_12, batch_1000] loss: 0.045
[epoch_12, batch_1050] loss: 0.036
[epoch_12, batch_1100] loss: 0.043
[epoch_12, batch_1150] loss: 0.045
[epoch_12, batch_1200] loss: 0.035
Traceback (most recent call last):
  File "train_pair_matching.py", line 133, in <module>
    train(continue_to_train, args)
  File "train_pair_matching.py", line 102, in train
    optimizer.zero_grad()
  File "/home/nttung/anaconda3/envs/detectron2/lib/python3.6/site-packages/torch/optim/optimizer.py", line 217, in zero_grad
    p.grad.zero_()
  File "/home/nttung/anaconda3/envs/detectron2/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3576734) is killed by signal: Killed.